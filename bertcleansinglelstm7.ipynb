{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google QUEST Q&A Labeling\n",
    "Improving automated understanding of complex question answer content\n",
    "\n",
    "Computers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences.\n",
    "\n",
    "Humans are better at addressing subjective questions that require a deeper, multidimensional understanding of context - something computers aren't trained to do well…yet.. Questions can take many forms - some have multi-sentence elaborations, others may be simple curiosity or a fully developed problem. They can have multiple intents, or seek advice and opinions. Some may be helpful and others interesting. Some are simple right or wrong.\n",
    "\n",
    "Unfortunately, it’s hard to build better subjective question-answering algorithms because of a lack of data and predictive models. That’s why the CrowdSource team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing, has collected data on a number of these quality scoring aspects.\n",
    "\n",
    "In this competition, you’re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get!\n",
    "\n",
    "Demonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{blue}{\\text{Summary of main results}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Each question_title, question_body and answer_body is fed into BERT pretrained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - The [cls] output from the last BERT layer for all of the above three is then concatenated and fed into a two layer LSTM, which is then fed into a dense layer with 30 outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Below BERT model is only used in evaluation mode bert_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - We get Spearman's correlation coefficient of upto 0.35 using this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - The results improve by using some tricks along the lines of \n",
    "https://github.com/rapat82/ReOrNot/blob/master/realornot-bertbase.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Obtaining sentence embeddings by just using the [CLS] token output from the last BERT layer typically does not constitute a good sentence representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Training many such models and combining their predictions using simple average increases performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - To run this notebook locally, change the path of data files and files for pretrained bert model accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/google-quest-challenge/test.csv\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased-vocab.txt\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-uncased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-cased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-multilingual-cased/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-base-chinese/bert_config.json\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased/pytorch_model.bin\n",
      "/kaggle/input/pretrained-bert-models-for-pytorch/bert-large-cased/bert_config.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_data = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv').fillna('')\n",
    "qa_testdata = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_title = qa_data['question_title'].values\n",
    "q_body = qa_data['question_body'].values\n",
    "a_body = qa_data['answer'].values\n",
    "q_test_title = qa_testdata['question_title'].values\n",
    "q_test_body = qa_testdata['question_body'].values\n",
    "a_test_body = qa_testdata['answer'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(input_list, m_len):\n",
    "    output_list = []\n",
    "    for i, row in enumerate(input_list):\n",
    "        output_list.append(tokenizer.encode(row, max_length=m_len, \n",
    "                                            truncation_strategy='longest_first', \n",
    "                                            pad_to_max_length=True, return_tensors='pt'))\n",
    "    output_tensor = torch.stack(output_list).squeeze()\n",
    "    return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  9 18:38:19 2020\n",
      "Sun Feb  9 18:39:46 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.ctime())\n",
    "q_title_num = numericalize(q_title, 30)\n",
    "q_body_num = numericalize(q_body, 120)\n",
    "a_body_num = numericalize(a_body, 150)\n",
    "q_test_title_num = numericalize(q_test_title, 30)\n",
    "q_test_body_num = numericalize(q_test_body, 120)\n",
    "a_test_body_num = numericalize(a_test_body, 150)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "y = qa_data[sample_submission.columns[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6079"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_title_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.55555556, 0.        , ..., 0.        , 0.        ,\n",
       "        0.88888889],\n",
       "       [0.66666667, 0.33333333, 0.        , ..., 0.33333333, 1.        ,\n",
       "        1.        ],\n",
       "       [0.88888889, 1.        , 0.33333333, ..., 0.        , 0.66666667,\n",
       "        0.88888889],\n",
       "       ...,\n",
       "       [0.77777778, 0.44444444, 0.        , ..., 0.        , 0.        ,\n",
       "        0.77777778],\n",
       "       [1.        , 0.66666667, 0.        , ..., 0.        , 0.33333333,\n",
       "        0.77777778],\n",
       "       [1.        , 0.55555556, 0.        , ..., 0.        , 1.        ,\n",
       "        0.88888889]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = np.random.permutation(q_title_num.shape[0])\n",
    "qtnum_shuffled = np.zeros_like(q_title_num)\n",
    "qbnum_shuffled = np.zeros_like(q_body_num)\n",
    "abnum_shuffled = np.zeros_like(a_body_num)\n",
    "labels_shuffled = np.zeros_like(y)\n",
    "np.take(q_title_num,perm,axis=0,out=qtnum_shuffled)\n",
    "np.take(q_body_num,perm,axis=0,out=qbnum_shuffled)\n",
    "np.take(a_body_num,perm,axis=0,out=abnum_shuffled)\n",
    "np.take(y,perm,axis=0,out=labels_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac=0.9\n",
    "iindex = int(len(q_title_num)*split_frac)\n",
    "qttrain_x, qbtrain_x, abtrain_x, qtval_x, qbval_x, abval_x = qtnum_shuffled[:iindex], qbnum_shuffled[:iindex], abnum_shuffled[:iindex], qtnum_shuffled[iindex:], qbnum_shuffled[iindex:], abnum_shuffled[iindex:]\n",
    "train_y, val_y = labels_shuffled[:iindex], labels_shuffled[iindex:] \n",
    "test_y = np.zeros((len(q_test_title_num), 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(qttrain_x))\n",
    "print(type(q_test_title_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 128\n",
    "test_bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(qttrain_x), torch.from_numpy(qbtrain_x), torch.from_numpy(abtrain_x), torch.from_numpy(train_y))\n",
    "val_data = TensorDataset(torch.from_numpy(qtval_x), torch.from_numpy(qbval_x), torch.from_numpy(abval_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(q_test_title_num, q_test_body_num, a_test_body_num, torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle = True, batch_size=train_bs)\n",
    "valid_loader = DataLoader(val_data, shuffle = True, batch_size=train_bs)\n",
    "test_loader = DataLoader(test_data, shuffle = False, batch_size=test_bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n",
      "torch.Size([128, 120])\n",
      "torch.Size([128, 150])\n",
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "qtx, qbx, abx, label = dataiter.next()\n",
    "print(qtx.shape)\n",
    "print(qbx.shape)\n",
    "print(abx.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n",
      "torch.Size([128, 120])\n",
      "torch.Size([128, 150])\n",
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "qtx, qbx, abx, label = dataiter.next()\n",
    "print(qtx.shape)\n",
    "print(qbx.shape)\n",
    "print(abx.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_model = BertModel.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased/', config = bert_config)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class QALSTM(nn.Module):\n",
    "    def __init__(self, seq_len, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \n",
    "        super(QALSTM, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim =embedding_dim\n",
    "        self.drop_prob = drop_prob\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, \n",
    "                           n_layers, dropout = drop_prob,\n",
    "                           batch_first = True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x1, x2, hidden):\n",
    "        batch_size = x1.size(0)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(lstm_output)\n",
    "        out = self.fc(out)\n",
    "        sigmoid_out = self.sigmoid(out)\n",
    "        sigmoid_out = sigmoid_out.view(batch_size, -1)\n",
    "        sigmoid_out = sigmoid_out[:,-30:]\n",
    "        return sigmoid_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            hidden=(weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden=(weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 30\n",
    "embedding_dim = 768\n",
    "hidden_dim = 1024\n",
    "n_layers = 2\n",
    "seq_len = 300\n",
    "net = QALSTM(seq_len, output_size, embedding_dim, hidden_dim, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/19---finished---score:0.12706756350622106---time:Sun Feb  9 18:41:14 2020, Sun Feb  9 18:39:58 2020\n",
      "Epoch: 2/19---finished---score:0.21214785115791956---time:Sun Feb  9 18:42:30 2020, Sun Feb  9 18:41:14 2020\n",
      "Epoch: 3/19---finished---score:0.22457610824814958---time:Sun Feb  9 18:43:46 2020, Sun Feb  9 18:42:30 2020\n",
      "Epoch: 4/19---finished---score:0.23196185373849876---time:Sun Feb  9 18:45:02 2020, Sun Feb  9 18:43:46 2020\n",
      "Epoch: 5/19---finished---score:0.24493890957571007---time:Sun Feb  9 18:46:19 2020, Sun Feb  9 18:45:02 2020\n",
      "Epoch: 6/19---finished---score:0.2594900885056537---time:Sun Feb  9 18:47:35 2020, Sun Feb  9 18:46:19 2020\n",
      "Epoch: 7/19---finished---score:0.2706110362480822---time:Sun Feb  9 18:48:51 2020, Sun Feb  9 18:47:35 2020\n",
      "Epoch: 8/19---finished---score:0.27509257309712876---time:Sun Feb  9 18:50:07 2020, Sun Feb  9 18:48:51 2020\n",
      "Epoch: 9/19---finished---score:0.2862974360141058---time:Sun Feb  9 18:51:23 2020, Sun Feb  9 18:50:07 2020\n",
      "Epoch: 10/19---finished---score:0.3013035826254557---time:Sun Feb  9 18:52:39 2020, Sun Feb  9 18:51:23 2020\n",
      "Epoch: 11/19---finished---score:0.30718682534534303---time:Sun Feb  9 18:53:56 2020, Sun Feb  9 18:52:39 2020\n",
      "Epoch: 12/19---finished---score:0.31262108824486023---time:Sun Feb  9 18:55:12 2020, Sun Feb  9 18:53:56 2020\n",
      "Epoch: 13/19---finished---score:0.31426971261857173---time:Sun Feb  9 18:56:28 2020, Sun Feb  9 18:55:12 2020\n",
      "Epoch: 14/19---finished---score:0.32316092546105657---time:Sun Feb  9 18:57:45 2020, Sun Feb  9 18:56:28 2020\n",
      "Epoch: 15/19---finished---score:0.33124547856867786---time:Sun Feb  9 18:59:01 2020, Sun Feb  9 18:57:45 2020\n",
      "Epoch: 16/19---finished---score:0.3311988344202036---time:Sun Feb  9 19:00:17 2020, Sun Feb  9 18:59:01 2020\n",
      "Epoch: 17/19---finished---score:0.34310762101194786---time:Sun Feb  9 19:01:33 2020, Sun Feb  9 19:00:17 2020\n",
      "Epoch: 18/19---finished---score:0.34364188696965586---time:Sun Feb  9 19:02:49 2020, Sun Feb  9 19:01:33 2020\n",
      "Epoch: 19/19---finished---score:0.3513744137944228---time:Sun Feb  9 19:04:06 2020, Sun Feb  9 19:02:49 2020\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "epochs = 19\n",
    "clip = 5 # Gradient clipping\n",
    "\n",
    "# If GPU is available, train on GPU\n",
    "if (train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# Now our network is in training mode, lets train for some epochs\n",
    "#accuracy_old_old =0.0\n",
    "loss_vs_epoch = []\n",
    "valloss_vs_epoch = []\n",
    "score_old = 0.0\n",
    "valid_loss_old = 100.0\n",
    "bert_model.to('cuda')\n",
    "bert_bs = 128\n",
    "for e in range(0,epochs):\n",
    "    t1=time.ctime()\n",
    "    for qtx, qbx, abx, labels in train_loader:\n",
    "        bert_qt_loader = DataLoader(qtx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        bert_qb_loader = DataLoader(qbx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        bert_ab_loader = DataLoader(abx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        with torch.no_grad():\n",
    "            qt_embed = []\n",
    "            qb_embed = []\n",
    "            ab_embed = []\n",
    "            for qt in bert_qt_loader:\n",
    "                qt = qt.to('cuda')\n",
    "                outputs_qt = bert_model(qt)[0]\n",
    "                qt_embed.append(outputs_qt)\n",
    "            for qb in bert_qb_loader:\n",
    "                qb = qb.to('cuda')\n",
    "                outputs_qb = bert_model(qb)[0] \n",
    "                qb_embed.append(outputs_qb)\n",
    "            for ab in bert_ab_loader:\n",
    "                ab = ab.to('cuda')\n",
    "                outputs_ab = bert_model(ab)[0]\n",
    "                ab_embed.append(outputs_ab)\n",
    "            qt_tensor=torch.cat(qt_embed)\n",
    "            qb_tensor=torch.cat(qb_embed)\n",
    "            a_feat=torch.cat(ab_embed)\n",
    "            q_feat = torch.cat((qt_tensor, qb_tensor), dim =1)\n",
    "        x1=q_feat\n",
    "        x2=a_feat\n",
    "        batch_size=qtx.shape[0]\n",
    "        h = net.init_hidden(batch_size)\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            x1, x2, labels = x1.cuda(), x2.cuda(), labels.cuda()\n",
    "        h = tuple([each.data for each in h])\n",
    "        net.zero_grad()\n",
    "        output, h = net(x1, x2, h)\n",
    "        loss = criterion(output, labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    loss_vs_epoch.append([e+1, loss.item()])\n",
    "    val_losses = []\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    original = []\n",
    "    for qtvx, qbvx, abvx, labels in valid_loader:\n",
    "        bert_qt_loader = DataLoader(qtvx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        bert_qb_loader = DataLoader(qbvx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        bert_ab_loader = DataLoader(abvx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "        with torch.no_grad():\n",
    "            qt_embed = []\n",
    "            qb_embed = []\n",
    "            ab_embed = []\n",
    "            for qt in bert_qt_loader:\n",
    "                qt = qt.to('cuda')\n",
    "                outputs_qt = bert_model(qt)[0]\n",
    "                qt_embed.append(outputs_qt)\n",
    "            for qb in bert_qb_loader:\n",
    "                qb = qb.to('cuda')\n",
    "                outputs_qb = bert_model(qb)[0] \n",
    "                qb_embed.append(outputs_qb)\n",
    "            for ab in bert_ab_loader:\n",
    "                ab = ab.to('cuda')\n",
    "                outputs_ab = bert_model(ab)[0]\n",
    "                ab_embed.append(outputs_ab)\n",
    "            qt_tensor=torch.cat(qt_embed)\n",
    "            qb_tensor=torch.cat(qb_embed)\n",
    "            a_feat=torch.cat(ab_embed)\n",
    "            q_feat = torch.cat((qt_tensor, qb_tensor), dim =1)\n",
    "        val_x1=q_feat\n",
    "        val_x2=a_feat\n",
    "        batch_size = qtvx.shape[0]\n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        \n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "        if (train_on_gpu):\n",
    "            val_x1, val_x2, labels = val_x1.cuda(), val_x2.cuda(), labels.cuda()\n",
    "        output, val_h = net(val_x1, val_x2, val_h)\n",
    "        val_loss = criterion(output, labels.float())                \n",
    "        val_losses.append(val_loss.item())\n",
    "        preds.append(output.cpu().detach().numpy())\n",
    "        original.append(labels.float().cpu().detach().numpy())\n",
    "    score = 0\n",
    "    for i in range(30):\n",
    "        score += np.nan_to_num(\n",
    "                spearmanr(np.concatenate(original)[:, i], \n",
    "                          np.concatenate(preds)[:, i]).correlation / 30)\n",
    "    valid_loss = np.mean(val_losses)\n",
    "    valloss_vs_epoch.append([e+1, np.mean(val_losses)])\n",
    "    if score > score_old:\n",
    "        score_old = score\n",
    "        model_name = 'best_model.net'\n",
    "        checkpoint = {'output_size': net.output_size,\n",
    "                     'embedding_dim': net.embedding_dim,\n",
    "                     'hidden_dim': net.hidden_dim,\n",
    "                     'n_layers':net.n_layers,\n",
    "                     'state_dict': net.state_dict()}\n",
    "        with open(model_name, 'wb') as f:\n",
    "            torch.save(checkpoint, f)    \n",
    "    net.train()\n",
    "    t2=time.ctime()\n",
    "    #etime = t2 - t1\n",
    "    print( \"Epoch: {}/{}---finished---score:{}---time:{}, {}\".format(e+1,epochs, score, t2, t1))\n",
    "\n",
    "loss_vs_epoch = np.array(loss_vs_epoch)\n",
    "valloss_vs_epoch = np.array(valloss_vs_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.42199213]\n",
      " [ 2.          0.41335413]\n",
      " [ 3.          0.41024854]\n",
      " [ 4.          0.40622871]\n",
      " [ 5.          0.40145983]\n",
      " [ 6.          0.4034024 ]\n",
      " [ 7.          0.39705639]\n",
      " [ 8.          0.39863102]\n",
      " [ 9.          0.39372438]\n",
      " [10.          0.39002605]\n",
      " [11.          0.38912213]\n",
      " [12.          0.38817714]\n",
      " [13.          0.38669078]\n",
      " [14.          0.38744558]\n",
      " [15.          0.38238826]\n",
      " [16.          0.38358501]\n",
      " [17.          0.38155003]\n",
      " [18.          0.38250473]\n",
      " [19.          0.3796507 ]]\n"
     ]
    }
   ],
   "source": [
    "print(valloss_vs_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('best_model.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "loaded = QALSTM(seq_len, checkpoint['output_size'], checkpoint['embedding_dim'],\n",
    "                     checkpoint['hidden_dim'],checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.cuda()\n",
    "loaded.eval()\n",
    "preds = []\n",
    "for qttx, qbtx, abtx, labels in test_loader:    \n",
    "    bert_qt_loader = DataLoader(qttx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "    bert_qb_loader = DataLoader(qbtx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "    bert_ab_loader = DataLoader(abtx, shuffle = False, batch_size=bert_bs, drop_last=False)\n",
    "    with torch.no_grad():\n",
    "        qt_embed = []\n",
    "        qb_embed = []\n",
    "        ab_embed = []\n",
    "        for qt in bert_qt_loader:\n",
    "            qt = qt.to('cuda')\n",
    "            outputs_qt = bert_model(qt)[0]\n",
    "            qt_embed.append(outputs_qt)\n",
    "        for qb in bert_qb_loader:\n",
    "            qb = qb.to('cuda')\n",
    "            outputs_qb = bert_model(qb)[0] \n",
    "            qb_embed.append(outputs_qb)\n",
    "        for ab in bert_ab_loader:\n",
    "            ab = ab.to('cuda')\n",
    "            outputs_ab = bert_model(ab)[0]\n",
    "            ab_embed.append(outputs_ab)\n",
    "        qt_tensor=torch.cat(qt_embed)\n",
    "        qb_tensor=torch.cat(qb_embed)\n",
    "        a_feat=torch.cat(ab_embed)\n",
    "        q_feat = torch.cat((qt_tensor, qb_tensor), dim =1)\n",
    "    test_x1=q_feat\n",
    "    test_x2=a_feat\n",
    "    batch_size=qttx.shape[0]\n",
    "    test_h = loaded.init_hidden(batch_size)\n",
    "    if (train_on_gpu):\n",
    "        test_x1, test_x2, labels = test_x1.cuda(), test_x2.cuda(), labels.cuda()\n",
    "    test_h = tuple([each.data for each in test_h])\n",
    "    output, test_h = loaded(test_x1, test_x2, test_h)\n",
    "    y_pred = output.detach()\n",
    "    preds.append(y_pred.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_list = []\n",
    "for i in range(len(test_loader)):\n",
    "    submit_list.append(preds[i].numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 30)\n"
     ]
    }
   ],
   "source": [
    "nsub = np.concatenate(submit_list)\n",
    "print(nsub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = ['question_asker_intent_understanding',\n",
    "          'question_body_critical',\n",
    "          'question_conversational',\n",
    "          'question_expect_short_answer',\n",
    "          'question_fact_seeking',\n",
    "          'question_has_commonly_accepted_answer',\n",
    "          'question_interestingness_others',\n",
    "          'question_interestingness_self',\n",
    "          'question_multi_intent',\n",
    "          'question_not_really_a_question',\n",
    "          'question_opinion_seeking',\n",
    "          'question_type_choice',\n",
    "          'question_type_compare',\n",
    "          'question_type_consequence',\n",
    "          'question_type_definition',\n",
    "          'question_type_entity',\n",
    "          'question_type_instructions',\n",
    "          'question_type_procedure',\n",
    "          'question_type_reason_explanation',\n",
    "          'question_type_spelling',\n",
    "          'question_well_written',\n",
    "          'answer_helpful',\n",
    "          'answer_level_of_information',\n",
    "          'answer_plausible',\n",
    "          'answer_relevance',\n",
    "          'answer_satisfaction',\n",
    "          'answer_type_instructions',\n",
    "          'answer_type_procedure',\n",
    "          'answer_type_reason_explanation',\n",
    "          'answer_well_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(nsub, columns=TARGET).clip(0.00001, 0.999999)\n",
    "submission.insert(0,'qa_id',qa_testdata['qa_id'].values)\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa_id : 0\n",
      "question_asker_intent_understanding : 476\n",
      "question_body_critical : 476\n",
      "question_conversational : 476\n",
      "question_expect_short_answer : 476\n",
      "question_fact_seeking : 476\n",
      "question_has_commonly_accepted_answer : 476\n",
      "question_interestingness_others : 476\n",
      "question_interestingness_self : 476\n",
      "question_multi_intent : 476\n",
      "question_not_really_a_question : 476\n",
      "question_opinion_seeking : 476\n",
      "question_type_choice : 476\n",
      "question_type_compare : 476\n",
      "question_type_consequence : 476\n",
      "question_type_definition : 476\n",
      "question_type_entity : 476\n",
      "question_type_instructions : 476\n",
      "question_type_procedure : 476\n",
      "question_type_reason_explanation : 476\n",
      "question_type_spelling : 476\n",
      "question_well_written : 476\n",
      "answer_helpful : 476\n",
      "answer_level_of_information : 476\n",
      "answer_plausible : 476\n",
      "answer_relevance : 476\n",
      "answer_satisfaction : 476\n",
      "answer_type_instructions : 476\n",
      "answer_type_procedure : 476\n",
      "answer_type_reason_explanation : 476\n",
      "answer_well_written : 476\n"
     ]
    }
   ],
   "source": [
    "for column in submission.columns:\n",
    "    print(column,\":\",sum(submission[column].between(0.00001,0.999999)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
